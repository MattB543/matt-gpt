from sqlmodel import Field, SQLModel, Column, JSON
from pgvector.sqlalchemy import Vector
from datetime import datetime
from typing import Optional, List
import uuid


class Message(SQLModel, table=True):
    __tablename__ = "messages"

    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    source: str = Field(index=True)  # 'slack', 'text', or 'matt-gpt conversation'
    thread_id: Optional[str] = Field(index=True)
    message_text: str
    timestamp: datetime = Field(index=True)
    sent: bool = Field(index=True)  # True if Matt sent it, False if received
    from_matt_gpt: bool = Field(default=False, index=True)  # True if generated by Matt-GPT
    embedding: Optional[list[float]] = Field(
        default=None, sa_column=Column(Vector(1536))  # OpenAI text-embedding-3-small
    )
    meta_data: dict = Field(default={}, sa_column=Column(JSON))
    created_at: datetime = Field(default_factory=datetime.utcnow)


class PersonalityDoc(SQLModel, table=True):
    __tablename__ = "personality_docs"

    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    doc_type: str = Field(index=True)
    title: str
    content: str
    summary: Optional[str]
    embedding: Optional[list[float]] = Field(
        default=None, sa_column=Column(Vector(1536))
    )
    meta_data: dict = Field(default={}, sa_column=Column(JSON))
    created_at: datetime = Field(default_factory=datetime.utcnow)


class QueryLog(SQLModel, table=True):
    """Track all queries and responses for analysis"""
    __tablename__ = "query_logs"

    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    conversation_id: uuid.UUID = Field(index=True)  # NEW: Track conversation continuity
    query_text: str
    response_text: str
    model_used: str
    context_used: dict = Field(sa_column=Column(JSON))  # Store RAG results
    tokens_used: int
    latency_ms: float
    ip_address: Optional[str]
    user_agent: Optional[str]
    meta_data: dict = Field(default={}, sa_column=Column(JSON))
    created_at: datetime = Field(default_factory=datetime.utcnow, index=True)


class RagAnalytics(SQLModel, table=True):
    """Track enhanced RAG system performance and analytics"""
    __tablename__ = "rag_analytics"
    
    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    query_id: uuid.UUID = Field(index=True)  # Links to QueryLog
    original_query: str
    expanded_queries: List[str] = Field(sa_column=Column(JSON))
    
    # Retrieval metrics
    total_messages_retrieved: int
    unique_messages_after_dedup: int
    threads_reconstructed: int
    
    # Filtering metrics  
    messages_before_filtering: int
    messages_after_filtering: int
    filtering_ratio: float  # after/before
    
    # Context data for analysis
    raw_retrieved_context: List[str] = Field(sa_column=Column(JSON))
    filtered_context: List[str] = Field(sa_column=Column(JSON))
    
    # Performance timing
    query_expansion_ms: float
    retrieval_ms: float
    filtering_ms: float
    total_rag_ms: float
    
    # Quality metrics
    context_relevance_score: Optional[float] = None
    fallback_used: bool = Field(default=False)  # Whether enhanced RAG failed and fell back
    
    created_at: datetime = Field(default_factory=datetime.utcnow, index=True)